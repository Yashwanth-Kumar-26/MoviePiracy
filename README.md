# ğŸ¬ Video Piracy Detection System

A hackathon-friendly Python solution that detects whether a recorded video is a pirated copy of an original video using perceptual image similarity and audio spectrogram matching.

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.8+** installed
2. **FFmpeg** installed and in PATH
   - Ubuntu/Debian: `sudo apt install ffmpeg`
   - macOS: `brew install ffmpeg`
   - Windows: Download from [ffmpeg.org](https://ffmpeg.org/download.html)

### Installation

```bash
# Install Python dependencies
pip install -r requirements.txt
```

### Usage

1. Place your video files in the project directory:
   - `originalvideo.mp4` (the original content)
   - `recordedvideo.mp4` (the potentially pirated content)

2. Run the detection system:
   ```bash
   python main.py
   ```

## ğŸ“ Project Structure

```
CineTry/
â”œâ”€â”€ config.py              # Configuration constants
â”œâ”€â”€ utils.py               # FFmpeg wrapper utilities
â”œâ”€â”€ reference_extractor.py # Phase 1: Extract from original
â”œâ”€â”€ recorded_extractor.py  # Phase 2: Extract from recorded
â”œâ”€â”€ comparator.py          # Phase 3: Compare & decide
â”œâ”€â”€ main.py                # Main orchestrator
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # This file
â””â”€â”€ output/                # Generated during execution
    â”œâ”€â”€ reference/         # Original screenshots & audio
    â”œâ”€â”€ recorded/          # Recorded screenshots & audio
    â”œâ”€â”€ metadata.json      # Extraction metadata
    â””â”€â”€ results.json       # Detection results
```

## ğŸ” How It Works

### Phase 1: Reference Generation
- Automatically selects random timestamps from the original video
- Extracts screenshots at those timestamps
- Extracts 15-second audio clips starting from those timestamps
- Saves metadata to JSON

### Phase 2: Recorded Video Extraction
- Reads timestamps from metadata
- Extracts screenshots and audio from the recorded video at the same timestamps

### Phase 3: Comparison & Decision
- **Image Comparison**: Uses perceptual hashing (pHash) to compare screenshots
  - Calculates Hamming distance between hashes
  - Threshold: distance â‰¤ 10 = match
- **Audio Comparison**: Uses mel spectrogram + cosine similarity
  - Threshold: similarity â‰¥ 0.7 = match
- **Decision Logic**:
  - If â‰¥50% screenshots match â†’ **PIRATED**
  - Else if audio similarity is high â†’ **PIRATED**
  - Else â†’ **NOT PIRATED**

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
NUM_SAMPLES = 4              # Number of random timestamps
AUDIO_DURATION = 15          # Audio clip duration (seconds)
IMAGE_HASH_THRESHOLD = 10    # Image similarity threshold
AUDIO_SIMILARITY_THRESHOLD = 0.7  # Audio similarity threshold
SCREENSHOT_MATCH_PERCENTAGE = 0.5  # 50% match required
```

## ğŸ“Š Example Output

```
==================================================
ğŸ¬ Video Piracy Detection System
==================================================

ğŸ“‚ Loading originalvideo.mp4...
   Duration: 04:05 (245.3s)
ğŸ² Generated random timestamps: [32, 88, 145, 210]

Phase 1: Extracting reference data...
  âœ“ Screenshot at 32s
  âœ“ Audio clip at 32s (15s duration)
  âœ“ Screenshot at 88s
  âœ“ Audio clip at 88s (15s duration)
  âœ“ Screenshot at 145s
  âœ“ Audio clip at 145s (15s duration)
  âœ“ Screenshot at 210s
  âœ“ Audio clip at 210s (15s duration)
ğŸ’¾ Metadata saved to output/metadata.json

Phase 2: Extracting from recorded video...
ğŸ“‚ Loaded recordedvideo.mp4
  âœ“ Screenshot at 32s
  âœ“ Audio clip at 32s (15s duration)
  âœ“ Screenshot at 88s
  âœ“ Audio clip at 88s (15s duration)
  âœ“ Screenshot at 145s
  âœ“ Audio clip at 145s (15s duration)
  âœ“ Screenshot at 210s
  âœ“ Audio clip at 210s (15s duration)

Phase 3: Comparing content...
ğŸ–¼ï¸  Visual match: 3 / 4 (75.0%)
ğŸ”Š Audio similarity: HIGH (avg: 0.85)

==================================================
ğŸš¨ RESULT: PIRATED
==================================================

Reason: Visual match 75.0% >= 50.0%

ğŸ“„ Detailed results saved to output/results.json
```

## ğŸ› ï¸ Testing Individual Modules

Each module can be tested independently:

```bash
# Test Phase 1 only
python reference_extractor.py

# Test Phase 2 only (requires Phase 1 to run first)
python recorded_extractor.py

# Test Phase 3 only (requires Phase 1 & 2 to run first)
python comparator.py
```

## ğŸ¯ Key Features

- âœ… **No external APIs** - Everything runs locally
- âœ… **No deep learning** - Uses classical signal processing
- âœ… **Perceptual comparison** - Not pixel-perfect matching
- âœ… **Robust to screen recording** - Handles compression, scaling, etc.
- âœ… **Demo-friendly output** - Clear, colorful console logs
- âœ… **Modular design** - Easy to understand and modify
- âœ… **Error handling** - Graceful failures with helpful messages

## ğŸ“ Notes

- The system uses **perceptual hashing** for images, which is robust to minor changes like compression, scaling, and color adjustments
- **Audio comparison** uses mel spectrograms, which capture the perceptual characteristics of sound
- Random timestamps help avoid false positives from common intro/outro sequences
- The system automatically handles videos of different lengths

## ğŸ› Troubleshooting

**"FFmpeg not found"**
- Ensure FFmpeg is installed and in your system PATH
- Test with: `ffmpeg -version`

**"No reference samples were extracted"**
- Check that `originalvideo.mp4` exists and is a valid video file
- Ensure FFmpeg can read the video format

**Low detection accuracy**
- Adjust thresholds in `config.py`
- Increase `NUM_SAMPLES` for more comparison points
- Check that videos are actually related

## ğŸ“„ License

MIT License - Free for hackathon use!
